{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! hdfs dfs -put /home/train/Downloads/flo100k.csv/ /user/train/datasets/flo100k.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 items\r\n",
      "-rw-r--r--   1 train supergroup       4556 2020-09-23 20:56 /user/train/datasets/Advertising.csv\r\n",
      "-rw-r--r--   1 train supergroup     674856 2024-06-23 15:11 /user/train/datasets/Churn_Modelling.csv\r\n",
      "drwxr-xr-x   - train supergroup          0 2020-11-19 21:02 /user/train/datasets/churn-telecom\r\n",
      "drwxr-xr-x   - train supergroup          0 2020-11-21 11:16 /user/train/datasets/retail_db\r\n",
      "-rw-r--r--   1 train supergroup   19589922 2024-06-24 09:42 /user/train/datasets/tflo100k.csv\r\n",
      "-rw-r--r--   1 train supergroup     460676 2024-06-21 19:41 /user/train/datasets/train.csv\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /user/train/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(\"/opt/manual/spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "       .appName(\"Flo Clustering\")\n",
    "       .master(\"yarn\")\n",
    "       .config(\"spark.sql.shuffle.partitions\", \"2\")\n",
    "       .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"delimiter\", '|').option(\"header\", True).option(\"inferSchema\", True).load(\"/user/train/datasets/tflo100k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[master_id: string, order_channel: string, platform_type: string, last_order_channel: string, first_order_date: timestamp, last_order_date: timestamp, last_order_date_online: timestamp, last_order_date_offline: timestamp, order_num_total_ever_online: double, order_num_total_ever_offline: double, customer_value_total_ever_offline: double, customer_value_total_ever_online: double, interested_in_categories_12: string, online_product_group_amount_top_name_12: string, offline_product_group_name_12: string, last_order_date_new: string, store_type: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>master_id</th>\n",
       "      <th>order_channel</th>\n",
       "      <th>platform_type</th>\n",
       "      <th>last_order_channel</th>\n",
       "      <th>first_order_date</th>\n",
       "      <th>last_order_date</th>\n",
       "      <th>last_order_date_online</th>\n",
       "      <th>last_order_date_offline</th>\n",
       "      <th>order_num_total_ever_online</th>\n",
       "      <th>order_num_total_ever_offline</th>\n",
       "      <th>customer_value_total_ever_offline</th>\n",
       "      <th>customer_value_total_ever_online</th>\n",
       "      <th>interested_in_categories_12</th>\n",
       "      <th>online_product_group_amount_top_name_12</th>\n",
       "      <th>offline_product_group_name_12</th>\n",
       "      <th>last_order_date_new</th>\n",
       "      <th>store_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b3ace094-a17f-11e9-a2fc-000d3a38a36f</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>2019-02-23 12:59:17</td>\n",
       "      <td>2019-02-23 12:59:17</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-02-23 12:59:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>212.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-02-23</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c57d7c4c-a950-11e9-a2fc-000d3a38a36f</td>\n",
       "      <td>Offline</td>\n",
       "      <td>OmniChannel</td>\n",
       "      <td>Offline</td>\n",
       "      <td>2019-12-01 16:48:09</td>\n",
       "      <td>2019-12-01 16:48:09</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-12-01 16:48:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>199.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>602897a6-cdac-11ea-b31f-000d3a38a36f</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>2020-07-24 15:49:47</td>\n",
       "      <td>2020-07-24 15:49:47</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-07-24 15:49:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[ERKEK]</td>\n",
       "      <td>None</td>\n",
       "      <td>ERKEK</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>388e4c4e-af86-11e9-a2fc-000d3a38a36f</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Online</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>2018-12-31 07:22:07</td>\n",
       "      <td>2018-12-31 07:22:07</td>\n",
       "      <td>2018-12-31 07:22:07</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>174.99</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80664354-adf0-11eb-8f64-000d3a299ebf</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>Online</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2021-05-05 21:07:02</td>\n",
       "      <td>2021-05-05 22:39:36</td>\n",
       "      <td>2021-05-05 22:39:36</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>283.95</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              master_id order_channel platform_type  \\\n",
       "0  b3ace094-a17f-11e9-a2fc-000d3a38a36f       Offline       Offline   \n",
       "1  c57d7c4c-a950-11e9-a2fc-000d3a38a36f       Offline   OmniChannel   \n",
       "2  602897a6-cdac-11ea-b31f-000d3a38a36f       Offline       Offline   \n",
       "3  388e4c4e-af86-11e9-a2fc-000d3a38a36f        Mobile        Online   \n",
       "4  80664354-adf0-11eb-8f64-000d3a299ebf       Desktop        Online   \n",
       "\n",
       "  last_order_channel    first_order_date     last_order_date  \\\n",
       "0            Offline 2019-02-23 12:59:17 2019-02-23 12:59:17   \n",
       "1            Offline 2019-12-01 16:48:09 2019-12-01 16:48:09   \n",
       "2            Offline 2020-07-24 15:49:47 2020-07-24 15:49:47   \n",
       "3             Mobile 2018-12-31 07:22:07 2018-12-31 07:22:07   \n",
       "4            Desktop 2021-05-05 21:07:02 2021-05-05 22:39:36   \n",
       "\n",
       "  last_order_date_online last_order_date_offline  order_num_total_ever_online  \\\n",
       "0                    NaT     2019-02-23 12:59:17                          NaN   \n",
       "1                    NaT     2019-12-01 16:48:09                          NaN   \n",
       "2                    NaT     2020-07-24 15:49:47                          NaN   \n",
       "3    2018-12-31 07:22:07                     NaT                          1.0   \n",
       "4    2021-05-05 22:39:36                     NaT                          2.0   \n",
       "\n",
       "   order_num_total_ever_offline  customer_value_total_ever_offline  \\\n",
       "0                           1.0                             212.98   \n",
       "1                           1.0                             199.98   \n",
       "2                           1.0                             140.49   \n",
       "3                           NaN                               0.00   \n",
       "4                           NaN                               0.00   \n",
       "\n",
       "   customer_value_total_ever_online interested_in_categories_12  \\\n",
       "0                              0.00                        None   \n",
       "1                              0.00                        None   \n",
       "2                              0.00                     [ERKEK]   \n",
       "3                            174.99                        None   \n",
       "4                            283.95                          []   \n",
       "\n",
       "  online_product_group_amount_top_name_12 offline_product_group_name_12  \\\n",
       "0                                    None                          None   \n",
       "1                                    None                          None   \n",
       "2                                    None                         ERKEK   \n",
       "3                                    None                          None   \n",
       "4                                    None                          None   \n",
       "\n",
       "  last_order_date_new store_type  \n",
       "0          2019-02-23          A  \n",
       "1          2019-12-01          A  \n",
       "2          2020-07-24          A  \n",
       "3          2018-12-31          A  \n",
       "4          2021-05-05          A  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "df_count = df.count()\n",
    "\n",
    "print(df_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- master_id: string (nullable = true)\n",
      " |-- order_channel: string (nullable = true)\n",
      " |-- platform_type: string (nullable = true)\n",
      " |-- last_order_channel: string (nullable = true)\n",
      " |-- first_order_date: timestamp (nullable = true)\n",
      " |-- last_order_date: timestamp (nullable = true)\n",
      " |-- last_order_date_online: timestamp (nullable = true)\n",
      " |-- last_order_date_offline: timestamp (nullable = true)\n",
      " |-- order_num_total_ever_online: double (nullable = true)\n",
      " |-- order_num_total_ever_offline: double (nullable = true)\n",
      " |-- customer_value_total_ever_offline: double (nullable = true)\n",
      " |-- customer_value_total_ever_online: double (nullable = true)\n",
      " |-- interested_in_categories_12: string (nullable = true)\n",
      " |-- online_product_group_amount_top_name_12: string (nullable = true)\n",
      " |-- offline_product_group_name_12: string (nullable = true)\n",
      " |-- last_order_date_new: string (nullable = true)\n",
      " |-- store_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()   # df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NULL CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_count(df, col_name):\n",
    "    nc = df.select(col_name).filter(\n",
    "        (F.col(col_name).isNull()) | \n",
    "        (F.col(col_name)=='') |\n",
    "        (F.col(col_name)=='NA')\n",
    "    ).count()\n",
    "    \n",
    "    return nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_order_date_online has 70784 % 70.784\n",
      "last_order_date_offline has 21703 % 21.703\n",
      "order_num_total_ever_online has 70784 % 70.784\n",
      "order_num_total_ever_offline has 21703 % 21.703\n",
      "interested_in_categories_12 has 56590 % 56.589999999999996\n",
      "online_product_group_amount_top_name_12 has 88295 % 88.295\n",
      "offline_product_group_name_12 has 77209 % 77.209\n"
     ]
    }
   ],
   "source": [
    "for col in df.dtypes:\n",
    "    nc = null_count(df, col[0])\n",
    "    \n",
    "    if nc > 0:\n",
    "        print(\"{} has {} % {}\".format(col[0], nc, (nc / df_count *100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|count(DISTINCT master_id)|\n",
      "+-------------------------+\n",
      "|                   100000|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can say that the master_id variable is unique() when the number of uniques of master_id is equal to the total number of rows of the data set.\n",
    "\n",
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "df.select(countDistinct(\"master_id\")).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-----+\n",
      "|platform_type|order_channel|count|\n",
      "+-------------+-------------+-----+\n",
      "|  OmniChannel|      Offline| 4793|\n",
      "|       Online|      Ios App| 3008|\n",
      "|       Online|       Mobile| 6451|\n",
      "|      Offline|      Offline|65991|\n",
      "|       Online|  Android App| 8728|\n",
      "|  OmniChannel|  Android App| 3261|\n",
      "|       Online|      Desktop| 3253|\n",
      "|  OmniChannel|      Ios App|  956|\n",
      "|  OmniChannel|      Desktop| 1498|\n",
      "|  OmniChannel|       Mobile| 2061|\n",
      "+-------------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy([\"platform_type\", \"order_channel\"]).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Before creating new variables, we need to convert the null values of these variables to zero and make sure that all values are greater than or equal to zero.\n",
    "\n",
    "# fill 'NA' with zero(0)\n",
    "\n",
    "df = df.na.fill(value = 0, subset = [\"order_num_total_ever_online\", \"order_num_total_ever_offline\", \"customer_value_total_ever_offline\", \"customer_value_total_ever_online\"])\n",
    "\n",
    "df = df.filter((df.order_num_total_ever_online >= 0) & (df.order_num_total_ever_offline >= 0) & (df.customer_value_total_ever_offline >= 0)\n",
    "              & (df.customer_value_total_ever_online >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omnichannel refers to customers shopping both online and offline platforms.\n",
    "\n",
    "# 'withColumn()' either creates a new variable or assigns it to an existing column.\n",
    "\n",
    "# creating 'order_num_total' variable: amount of total shopping\n",
    "\n",
    "df = df.withColumn(\"order_num_total\", df.order_num_total_ever_online + df.order_num_total_ever_offline)\n",
    "\n",
    "\n",
    "# creating  'customer_value_total' variable: refers to amount of total money\n",
    "\n",
    "df = df.withColumn(\"customer_value_total\", df.customer_value_total_ever_online + df.customer_value_total_ever_offline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-------------------------+--------------------+\n",
      "|order_channel|count(master_id)|avg(customer_value_total)|avg(order_num_total)|\n",
      "+-------------+----------------+-------------------------+--------------------+\n",
      "|      Offline|           70784|       218.16394849129728|  1.6003475361663653|\n",
      "|      Ios App|            3964|        568.4640312815283|   3.377648839556004|\n",
      "|       Mobile|            8512|        391.7418761748012|   2.798637218045113|\n",
      "|  Android App|           11989|        532.8462840937639|    3.50971724080407|\n",
      "|      Desktop|            4751|       376.91355504103785|   2.538623447695222|\n",
      "+-------------+----------------+-------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total number of customers, average products and earnings distribution across order channels:\n",
    "\n",
    "df.groupBy(\"order_channel\").agg({\"master_id\": \"count\", \"order_num_total\": \"avg\", \"customer_value_total\":\"avg\"}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-------------------------+--------------------+\n",
      "|platform_type|count(master_id)|avg(customer_value_total)|avg(order_num_total)|\n",
      "+-------------+----------------+-------------------------+--------------------+\n",
      "|      Offline|           65991|        215.7303068601296|  1.5837917291751906|\n",
      "|  OmniChannel|           12569|        500.7937512928769|  3.4947092051873656|\n",
      "|       Online|           21440|        404.7896576492903|  2.6207089552238805|\n",
      "+-------------+----------------+-------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total number of customers, average products and earnings distribution across platform_type:\n",
    "\n",
    "df.groupBy(\"platform_type\").agg({\"master_id\": \"count\", \"order_num_total\": \"avg\", \"customer_value_total\":\"avg\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---------------+--------------------+\n",
      "|           master_id|last_order_date_new|order_num_total|customer_value_total|\n",
      "+--------------------+-------------------+---------------+--------------------+\n",
      "|b3ace094-a17f-11e...|         2019-02-23|            1.0|              212.98|\n",
      "|c57d7c4c-a950-11e...|         2019-12-01|            1.0|              199.98|\n",
      "|602897a6-cdac-11e...|         2020-07-24|            1.0|              140.49|\n",
      "|388e4c4e-af86-11e...|         2018-12-31|            1.0|              174.99|\n",
      "|80664354-adf0-11e...|         2021-05-05|            2.0|              283.95|\n",
      "+--------------------+-------------------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfm = df[[\"master_id\", \"last_order_date_new\", \"order_num_total\", \"customer_value_total\"]]\n",
    "\n",
    "rfm.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2021, 5, 30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last order date\n",
    "\n",
    "last_order_date = df.agg({\"last_order_date\":\"max\"}).collect()[0][0]\n",
    "\n",
    "last_order_date.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---------------+--------------------+-------+\n",
      "|           master_id|last_order_date_new|order_num_total|customer_value_total|Recency|\n",
      "+--------------------+-------------------+---------------+--------------------+-------+\n",
      "|b3ace094-a17f-11e...|         2019-02-23|            1.0|              212.98|    829|\n",
      "|c57d7c4c-a950-11e...|         2019-12-01|            1.0|              199.98|    548|\n",
      "|602897a6-cdac-11e...|         2020-07-24|            1.0|              140.49|    312|\n",
      "|388e4c4e-af86-11e...|         2018-12-31|            1.0|              174.99|    883|\n",
      "|80664354-adf0-11e...|         2021-05-05|            2.0|              283.95|     27|\n",
      "+--------------------+-------------------+---------------+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's calculate each customer's last purchase time in days,as  \n",
    "# two days after the last purchase date, and store it in a variable called \"Recency\".\n",
    "\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "rfm = rfm.withColumn(\"Recency\", expr(\"datediff('2021-6-1', last_order_date_new)\"))\n",
    "\n",
    "rfm.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---------+--------+-------+\n",
      "|           master_id|last_order_date_new|Frequency|Monetary|Recency|\n",
      "+--------------------+-------------------+---------+--------+-------+\n",
      "|b3ace094-a17f-11e...|         2019-02-23|      1.0|  212.98|    829|\n",
      "|c57d7c4c-a950-11e...|         2019-12-01|      1.0|  199.98|    548|\n",
      "|602897a6-cdac-11e...|         2020-07-24|      1.0|  140.49|    312|\n",
      "|388e4c4e-af86-11e...|         2018-12-31|      1.0|  174.99|    883|\n",
      "|80664354-adf0-11e...|         2021-05-05|      2.0|  283.95|     27|\n",
      "+--------------------+-------------------+---------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When we want to change the name, we use the 'withColumnRenamed' function.\n",
    "\n",
    "# order_num_total: Frequency\n",
    "# customer_value_total: Monetary\n",
    "\n",
    "rfm = (rfm.withColumnRenamed(\"order_num_total\", \"Frequency\").withColumnRenamed(\"customer_value_total\", \"Monetary\"))\n",
    "\n",
    "rfm.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------+-------+\n",
      "|           master_id|Frequency|Monetary|Recency|\n",
      "+--------------------+---------+--------+-------+\n",
      "|b3ace094-a17f-11e...|      1.0|  212.98|    829|\n",
      "|c57d7c4c-a950-11e...|      1.0|  199.98|    548|\n",
      "|602897a6-cdac-11e...|      1.0|  140.49|    312|\n",
      "|388e4c4e-af86-11e...|      1.0|  174.99|    883|\n",
      "|80664354-adf0-11e...|      2.0|  283.95|     27|\n",
      "+--------------------+---------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Removing unnecessary columns (\"last_order_date_new\")\n",
    "\n",
    "rfm = rfm.drop(\"last_order_date_new\")\n",
    "\n",
    "rfm.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_col = [\"Recency\", \"Frequency\", \"Monetary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = (VectorAssembler() \\\n",
    "            .setHandleInvalid(\"skip\") \\\n",
    "            .setInputCols(rfm_col) \\\n",
    "            .setOutputCol(\"unscaled_features\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler =  StandardScaler() \\\n",
    "         .setInputCol(\"unscaled_features\") \\\n",
    "         .setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline_obj = Pipeline().setStages([assembler, scaler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------+-------+------------------+--------------------+\n",
      "|           master_id|Frequency|Monetary|Recency| unscaled_features|            features|\n",
      "+--------------------+---------+--------+-------+------------------+--------------------+\n",
      "|b3ace094-a17f-11e...|      1.0|  212.98|    829|[829.0,1.0,212.98]|[3.24793811935259...|\n",
      "|c57d7c4c-a950-11e...|      1.0|  199.98|    548|[548.0,1.0,199.98]|[2.14700855175539...|\n",
      "|602897a6-cdac-11e...|      1.0|  140.49|    312|[312.0,1.0,140.49]|[1.22238443092642...|\n",
      "|388e4c4e-af86-11e...|      1.0|  174.99|    883|[883.0,1.0,174.99]|[3.45950465547447...|\n",
      "|80664354-adf0-11e...|      2.0|  283.95|     27| [27.0,2.0,283.95]|[0.10578326806094...|\n",
      "+--------------------+---------+--------+-------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_model = pipeline_obj.fit(rfm)\n",
    "\n",
    "transformed_df = pipeline_model.transform(rfm)\n",
    "\n",
    "transformed_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Optimum Cluster Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "def compute_KMeans_Model(df, k):\n",
    "    kmeansObject = KMeans() \\\n",
    "    .setSeed(142) \\\n",
    "    .setK(k)\n",
    "    \n",
    "    return kmeansObject.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " k: 2,  score:0.4403139929816374\n",
      " k: 3,  score:0.655033488104594\n",
      " k: 4,  score:0.6658979549823151\n",
      " k: 5,  score:0.6777415637605754\n",
      " k: 6,  score:0.5104147694093096\n",
      " k: 7,  score:0.6780801245958924\n",
      " k: 8,  score:0.6494848988252858\n",
      " k: 9,  score:0.5039729078361186\n",
      " k: 10,  score:0.5132605636800474\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "evaluator = ClusteringEvaluator()\n",
    "score_list = []\n",
    "\n",
    "for k in range(2,11):\n",
    "    kmeans_model = compute_KMeans_Model(transformed_df, k)\n",
    "    \n",
    "    transformed = kmeans_model.transform(transformed_df)\n",
    "    \n",
    "    score = evaluator.evaluate(transformed)\n",
    "    score_list.append(score)\n",
    "    \n",
    "    print(\" k: {},  score:{}\".format(k, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remodeling with optimum value\n",
    "\n",
    "kmeans = ( KMeans()\\\n",
    "           .setSeed(142) \\\n",
    "           .setK(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = kmeans.fit(transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------------+-------+--------------------+--------------------+----------+\n",
      "|           master_id|Frequency|          Monetary|Recency|   unscaled_features|            features|prediction|\n",
      "+--------------------+---------+------------------+-------+--------------------+--------------------+----------+\n",
      "|b3ace094-a17f-11e...|      1.0|            212.98|    829|  [829.0,1.0,212.98]|[3.24793811935259...|         2|\n",
      "|c57d7c4c-a950-11e...|      1.0|            199.98|    548|  [548.0,1.0,199.98]|[2.14700855175539...|         2|\n",
      "|602897a6-cdac-11e...|      1.0|            140.49|    312|  [312.0,1.0,140.49]|[1.22238443092642...|         0|\n",
      "|388e4c4e-af86-11e...|      1.0|            174.99|    883|  [883.0,1.0,174.99]|[3.45950465547447...|         2|\n",
      "|80664354-adf0-11e...|      2.0|            283.95|     27|   [27.0,2.0,283.95]|[0.10578326806094...|         0|\n",
      "|47511f36-aeb4-11e...|      1.0|            139.98|    933|  [933.0,1.0,139.98]|[3.65539959632807...|         2|\n",
      "|77f7c318-3407-11e...|      1.0|             269.9|    182|   [182.0,1.0,269.9]|[0.71305758470708...|         0|\n",
      "|399d6dd2-ecf1-11e...|      1.0|             95.73|    272|   [272.0,1.0,95.73]|[1.06566847824355...|         0|\n",
      "|b3d4a6f2-a368-11e...|      3.0|            207.94|    250|  [250.0,3.0,207.94]|[0.97947470426797...|         0|\n",
      "|42fdccd4-f1d1-11e...|      1.0|            134.95|    226|  [226.0,1.0,134.95]|[0.88544513265824...|         0|\n",
      "|071b497c-a5d2-11e...|      7.0|            399.94|     71|   [71.0,7.0,399.94]|[0.27817081601210...|         0|\n",
      "|47d99768-30ea-11e...|      2.0|            304.89|    667|  [667.0,2.0,304.89]|[2.61323851098695...|         2|\n",
      "|f879c85e-5322-11e...|      1.0|            100.49|    488|  [488.0,1.0,100.49]|[1.91193462273108...|         2|\n",
      "|cfb38c70-b1e7-11e...|      3.0|208.95999999999998|    507|[507.0,3.0,208.95...|[1.98637470025544...|         2|\n",
      "|96cae10c-bbd1-11e...|      2.0|            359.96|    335|  [335.0,2.0,359.96]|[1.31249610371908...|         0|\n",
      "|20df63fa-5411-11e...|      1.0|             39.99|    501|   [501.0,1.0,39.99]|[1.96286730735301...|         2|\n",
      "|757fc81a-7378-11e...|      2.0|            630.94|     67|   [67.0,2.0,630.94]|[0.26249922074381...|         0|\n",
      "|c9fcbc34-d739-11e...|      1.0|            289.99|    300|  [300.0,1.0,289.99]|[1.17536964512156...|         0|\n",
      "|9f44ad8c-21fc-11e...|      1.0|            189.99|    788|  [788.0,1.0,189.99]|[3.08730426785264...|         2|\n",
      "|3fcf9680-9765-11e...|      1.0|             89.99|    385|   [385.0,1.0,89.99]|[1.50839104457267...|         2|\n",
      "+--------------------+---------+------------------+-------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed = kmeans_model.transform(transformed_df)\n",
    "\n",
    "transformed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------+------------------+------------------+\n",
      "|prediction|count|      avg_monetary|       avg_recency|     avg_frequency|\n",
      "+----------+-----+------------------+------------------+------------------+\n",
      "|         1|    3|          37469.96| 536.6666666666666| 306.3333333333333|\n",
      "|         3|   17|13068.847058823529|169.05882352941177| 91.23529411764706|\n",
      "|         4| 4072|1544.8937328094296|189.84037328094303| 9.520383104125736|\n",
      "|         0|41794| 307.9166727281978|173.99028568694072|2.0373020050724984|\n",
      "|         2|54114|179.52782311424278| 615.5692427098348| 1.445928964778061|\n",
      "+----------+-----+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, desc, mean, count, col\n",
    "\n",
    "transformed.groupBy(\"prediction\") \\\n",
    "    .agg(\n",
    "        count(\"Monetary\").alias(\"count\"),\n",
    "        mean(\"Monetary\").alias(\"avg_monetary\"),\n",
    "        mean(\"Recency\").alias(\"avg_recency\"),\n",
    "        mean(\"Frequency\").alias(\"avg_frequency\")\n",
    "    ) \\\n",
    "    .orderBy(desc(\"avg_monetary\")) \\\n",
    "    .show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvspark",
   "language": "python",
   "name": "venvspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
